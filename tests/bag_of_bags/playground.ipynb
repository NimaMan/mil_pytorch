{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([361, 100]) 100\n",
      "INFO: Using device: cpu\n",
      "DEBUG: train: [78 49 66 50 69 14 94 63 12 25 26  6 97 88 80 34 86 92 64 36 81 20 28 44\n",
      "  5 52 31 57 85 43 16  2 22 95 72 24 45  4 32  3 96 58 76 89 75 23  7 65\n",
      " 74 71 55 18 15 21 10 40 83 70 79 90 56 59 47 42 30 61 84 17 33 19 87  0\n",
      " 37 11 73 60 99 82 62 53], valid: [], test: [39 54 13 27  1 38 67 98 77 48 93 41 35 51  8 29 68 46  9 91]\n",
      "INFO: Running cross validation with config:\n",
      "{'epochs': 4000, 'pos': 50, 'neg': 50, 'class_sep': 1.2, 'n_features': 100, 'max_subbags': 5, 'max_instances': 5, 'batch_size': 0, 'patience': 20, 'delta': 0, 'n_neurons1': 5, 'n_neurons2': 5, 'n_neurons3': 5, 'learning_rate': 0.0001, 'weight_decay': 0.0001}\n",
      "K-fold CV: [1/5]\n",
      "TRAINING:\n",
      "DEBUG: shape of data: torch.Size([236, 100]) shape of info: torch.Size([1, 236]) shape of labels: torch.Size([64])\n",
      "DEBUG: bags: tensor([65, 52, 62, 47, 79, 23, 99, 60, 75, 55, 19,  5, 30, 95,  0, 96, 40, 42,\n",
      "        33, 15, 20, 57, 70, 82, 83, 76, 45, 90, 53, 32,  2, 84, 24, 87, 92, 16,\n",
      "         3, 85, 44, 28, 81, 64, 59, 71, 56, 72,  4,  7, 36, 18, 61, 43, 37, 10,\n",
      "        22, 58, 31, 73, 17, 11, 21, 74, 86, 89]) NN_out[0]: tensor([0.1735, 0.7279, 0.0000, 0.0000, 0.2716], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward>)\n",
      "DEBUG: bags: tensor([], dtype=torch.float64, grad_fn=<IndexBackward>) NN_out[0]: 0.6040277417172177\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "len() of a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e01325354ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    152\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_fold_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0;31m# Save log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/kuba/code/aic/mil/mil_pytorch/utils/train_utils.py\u001b[0m in \u001b[0;36mk_fold_cv\u001b[0;34m(model, fit_fn, criterion, optimizer, dataset, train_indices, epochs, patience, delta, n_folds, print_loss, device)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Fit and save error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"K-fold CV: [{}/{}]\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mmin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/kuba/code/aic/mil/mil_pytorch/utils/train_utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, train_dl, valid_dl, epochs, patience, delta, device)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DEBUG: shape of data: {} shape of info: {} shape of labels: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/kuba/code/aic/mil/mil_pytorch/mil.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Allocate memory for output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DEBUG: bags: {} NN_out[0]: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNN_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"len() of a 0-d tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of a 0-d tensor"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/users/kuba/code/aic/mil')\n",
    "\n",
    "import mil_pytorch.mil as mil\n",
    "from mil_pytorch.utils import eval_utils, data_utils, train_utils, create_bags_simple\n",
    "\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.datasets import make_classification\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def create_model(n_neurons1, n_neurons2, n_neurons3):\n",
    "    # Define neural networks for processing of data before and after aggregation\n",
    "    prepNN1 = torch.nn.Sequential(\n",
    "        torch.nn.Linear(len(dataset.data[0]), n_neurons1, bias = True),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(n_neurons1, n_neurons2, bias = True),\n",
    "        torch.nn.ReLU(),\n",
    "    )\n",
    "\n",
    "    afterNN1 = torch.nn.Sequential(\n",
    "        torch.nn.Identity()\n",
    "    )\n",
    "\n",
    "    prepNN2 = torch.nn.Sequential(\n",
    "        torch.nn.Linear(n_neurons2, n_neurons3, bias = True),\n",
    "        torch.nn.ReLU(),\n",
    "    )\n",
    "\n",
    "    afterNN2 = torch.nn.Sequential(\n",
    "        torch.nn.Linear(n_neurons3, 1),\n",
    "        torch.nn.Tanh()\n",
    "    )\n",
    "\n",
    "    # Define model ,loss function and optimizer\n",
    "    model = torch.nn.Sequential(\n",
    "        mil.BagModel(prepNN1, afterNN1, torch.mean, device),\n",
    "        mil.BagModel(prepNN2, afterNN2, torch.mean, device)\n",
    "    ).double()\n",
    "    criterion = mil.MyHingeLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "\n",
    "    return model\n",
    "\n",
    "# --- CONFIG ---\n",
    "\n",
    "# Configurations\n",
    "n_neurons1 = None\n",
    "n_neurons2 = None\n",
    "n_neurons3 = None\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-3\n",
    "epochs = 4000\n",
    "pos = 50\n",
    "neg = 50\n",
    "class_sep = 1.2\n",
    "n_features = 100\n",
    "max_subbags = 5\n",
    "max_instances = 5\n",
    "batch_size = 0\n",
    "patience = 20\n",
    "delta = 0\n",
    "\n",
    "config = {}\n",
    "config['epochs'] = epochs\n",
    "config['pos'] = pos\n",
    "config['neg'] = neg\n",
    "config['class_sep'] = class_sep\n",
    "config['n_features'] = n_features\n",
    "config['max_subbags'] = max_subbags\n",
    "config['max_instances'] = max_instances\n",
    "config['batch_size'] = batch_size\n",
    "config['patience'] = patience\n",
    "config['delta'] = delta\n",
    "config[\"n_neurons1\"] = n_neurons1\n",
    "config[\"n_neurons2\"] = n_neurons2\n",
    "config[\"n_neurons3\"] = n_neurons3\n",
    "config[\"learning_rate\"] = learning_rate\n",
    "config[\"weight_decay\"] = weight_decay\n",
    "\n",
    "# --- DATA ---\n",
    "\n",
    "# Create data\n",
    "source_data, source_labels = make_classification(n_samples = 20000, n_features = n_features, n_informative = n_features, n_redundant = 0, n_repeated = 0, n_classes = 10, class_sep = class_sep, n_clusters_per_class = 1)\n",
    "data, ids, labels = create_bags_simple.create_bags(source_data, source_labels, pos = pos, neg = neg, max_instances = max_instances)\n",
    "print(\"Data shape:\", data.shape, len(labels))\n",
    "\n",
    "# Check if gpu available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"INFO: Using device: {}\".format(device))\n",
    "\n",
    "# Move data to gpu (if available)\n",
    "data = data.double().to(device)\n",
    "ids = ids.long().to(device)\n",
    "labels = labels.long().to(device)\n",
    "\n",
    "# Convert labels from (1, 0) to (1, -1) for tanh\n",
    "labels[labels == 0] = -1\n",
    "\n",
    "# Create dataset and divide to train and test part\n",
    "dataset = mil.MilDataset(data, ids, labels, normalize = True)\n",
    "\n",
    "train_indices, valid_indices, test_indices = data_utils.data_split(dataset = dataset, valid_ratio = 0.0, test_ratio = 0.2, shuffle = True, stratify = True)\n",
    "\n",
    "print('DEBUG: train: {}, valid: {}, test: {}'.format(train_indices, valid_indices, test_indices))\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "# valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "# Create dataloaders\n",
    "if batch_size == 0:\n",
    "    train_dl = DataLoader(dataset, sampler = train_sampler, batch_size = len(train_indices), collate_fn=mil.collate)\n",
    "else:\n",
    "    train_dl = DataLoader(dataset, sampler = train_sampler, batch_size = batch_size, collate_fn=mil.collate)\n",
    "\n",
    "# valid_dl = DataLoader(dataset, sampler = valid_sampler, batch_size = len(valid_indices), collate_fn=mil.collate)\n",
    "test_dl = DataLoader(dataset, sampler = test_sampler, batch_size = len(test_indices), collate_fn=mil.collate)\n",
    "\n",
    "\n",
    "# ---- GRID SEARCH ---\n",
    "\n",
    "n_neurons1_grid = [5, 10, 15]\n",
    "n_neurons2_grid = [5, 10, 15]\n",
    "n_neurons3_grid = [5, 10, 15]\n",
    "learning_rate_grid = numpy.logspace(-4, -2, num = 3)\n",
    "weight_decay_grid = numpy.logspace(-4, -2, num = 3)\n",
    "\n",
    "for n_neurons1 in n_neurons1_grid:\n",
    "    for n_neurons2 in n_neurons2_grid:\n",
    "        for n_neurons3 in n_neurons3_grid:\n",
    "            for learning_rate in learning_rate_grid:\n",
    "                for weight_decay in weight_decay_grid:\n",
    "                    config['n_neurons1'] = n_neurons1\n",
    "                    config['n_neurons2'] = n_neurons2\n",
    "                    config['n_neurons3'] = n_neurons3\n",
    "                    config['learning_rate'] = learning_rate.item()\n",
    "                    config['weight_decay'] = weight_decay.item()\n",
    "\n",
    "                    print('INFO: Running cross validation with config:\\n{}'.format(config))\n",
    " \n",
    "                    # --- MODEL ---\n",
    "                    model = create_model(n_neurons1, n_neurons2, n_neurons3)\n",
    "                    criterion = mil.MyHingeLoss()\n",
    "                    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "\n",
    "                    # Move model to gpu if available\n",
    "                    model = model.to(device)\n",
    "\n",
    "                    avg_loss = train_utils.k_fold_cv(model = model, fit_fn = train_utils.train_model, criterion = criterion, optimizer = optimizer, dataset = dataset, train_indices = train_indices, epochs = epochs, patience = patience, delta = delta, device = device)\n",
    "\n",
    "                    # Save log\n",
    "                    train_utils.save_log(avg_loss, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  3,  3,  3,  3,  4,  4,  5,  5,\n",
       "          5,  5,  5,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  8,  8,  8,  9,  9,\n",
       "         10, 10, 11, 11, 11, 12, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14, 15, 15,\n",
       "         15, 15, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18, 19, 19, 19, 19,\n",
       "         20, 20, 20, 20, 21, 21, 22, 22, 22, 22, 23, 23, 23, 23, 23, 24, 24, 24,\n",
       "         24, 25, 25, 25, 25, 25, 26, 26, 26, 26, 27, 27, 28, 28, 28, 29, 29, 29,\n",
       "         29, 30, 30, 31, 31, 31, 31, 32, 32, 32, 33, 33, 33, 33, 34, 34, 34, 34,\n",
       "         35, 35, 36, 36, 36, 37, 37, 38, 38, 38, 39, 39, 39, 40, 40, 40, 41, 41,\n",
       "         42, 42, 42, 42, 43, 43, 43, 44, 44, 44, 44, 44, 45, 45, 45, 46, 46, 46,\n",
       "         46, 47, 47, 47, 47, 47, 48, 48, 48, 49, 49, 49, 49, 49, 50, 50, 50, 50,\n",
       "         50, 51, 51, 52, 52, 52, 52, 53, 53, 53, 53, 53, 54, 54, 54, 54, 54, 55,\n",
       "         55, 56, 56, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 59, 59, 59, 60, 60,\n",
       "         60, 61, 61, 61, 61, 62, 62, 62, 62, 63, 63, 63, 63, 64, 64, 64, 64, 64,\n",
       "         65, 65, 65, 65, 65, 66, 66, 66, 67, 67, 67, 67, 68, 68, 69, 69, 69, 69,\n",
       "         70, 70, 70, 71, 71, 71, 72, 72, 72, 72, 72, 73, 73, 73, 73, 74, 74, 74,\n",
       "         74, 75, 75, 75, 75, 76, 76, 76, 76, 77, 77, 78, 78, 78, 78, 78, 79, 79,\n",
       "         79, 79, 79, 80, 80, 80, 81, 81, 81, 81, 82, 82, 82, 83, 83, 83, 83, 84,\n",
       "         84, 85, 85, 85, 85, 85, 86, 86, 86, 86, 87, 87, 87, 87, 88, 88, 89, 89,\n",
       "         89, 89, 89, 90, 90, 90, 90, 91, 91, 91, 92, 92, 92, 92, 92, 93, 93, 93,\n",
       "         93, 94, 94, 94, 95, 95, 95, 96, 96, 96, 97, 97, 97, 98, 98, 98, 98, 99,\n",
       "         99]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
