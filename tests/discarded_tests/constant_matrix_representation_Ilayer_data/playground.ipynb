{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "\n",
    "class BagModel_3d(nn.Module):\n",
    "    '''\n",
    "    BagModel_3d - not scalable, used with data represented in 3d\n",
    "    Accepts 3d data tensor and n_instances array\n",
    "    '''\n",
    "    def __init__(self, prepNN, afterNN, aggregation_func):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.prepNN = prepNN\n",
    "        self.afterNN = afterNN\n",
    "        self.aggregation_func = aggregation_func\n",
    "\n",
    "#     @profile\n",
    "    def forward(self, input, n_instances):\n",
    "        \n",
    "        NN_out = self.prepNN(input) # Forward all indices through neural network\n",
    "        \n",
    "        output = torch.empty(size = (input.size(0), len(NN_out[0][0])), dtype = torch.double) # Pre-alocate tensor for output\n",
    "\n",
    "        for i, n in enumerate(n_instances):\n",
    "            output[i] = self.aggregation_func(NN_out[i, :n], dim = 0) # Aggregates only valid instances\n",
    "            \n",
    "        output = self.afterNN(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    \n",
    "def create_3d_data(instances, n_instances):\n",
    "    ''' Create 3d tensor of data from 2d sequence of instances '''\n",
    "    max_n_instances = max(n_instances)\n",
    "    n_bags = len(n_instances)\n",
    "    n_features = instances.shape[1]\n",
    "    \n",
    "    # Pre-allocate empty 3d tensor\n",
    "    data = torch.empty(n_bags, max_n_instances, n_features)\n",
    "    \n",
    "    # Fill data tensor\n",
    "    marker = 0\n",
    "    for i in range(n_bags):\n",
    "        data[i] = torch.cat([ torch.tensor(instances[ marker : marker + n_instances[i] ]) ,  torch.zeros(max_n_instances - n_instances[i], n_features, dtype = torch.double) ], dim = 0)\n",
    "        marker += n_instances[i]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def ids2n_instances(ids):\n",
    "    unique, inverse, counts = torch.unique(ids, sorted = True, return_inverse = True, return_counts = True)\n",
    "    idx = torch.cat([(inverse == x).nonzero()[0] for x in range(len(unique))]).sort()[1]\n",
    "    bags = unique[idx]\n",
    "    counts = counts[idx]\n",
    "    \n",
    "    return counts\n",
    "\n",
    "def data_split_3d(data, labels, n_instances, shuffle, test_size = 0.2):\n",
    "    data = numpy.array(data)\n",
    "    labels = numpy.array(labels)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, n_instances, n_instances_t = \\\n",
    "        model_selection.train_test_split(data, labels, n_instances, test_size = test_size, shuffle = shuffle)\n",
    "    \n",
    "    y = torch.from_numpy(y_train)\n",
    "    x = torch.from_numpy(X_train)\n",
    "    x_t = torch.from_numpy(X_test)\n",
    "    y_t = torch.from_numpy(y_test)\n",
    "    \n",
    "    return x, x_t, y, y_t, n_instances, n_instances_t\n",
    "\n",
    "def accuracy(pred, target, threshold = 0):\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    pred = pred.detach().numpy()\n",
    "    target = target.detach().numpy()\n",
    "\n",
    "    pred[pred >= threshold] = 1\n",
    "    pred[pred < threshold] = -1\n",
    "\n",
    "    return numpy.sum(target == pred)/target.shape[0]\n",
    "\n",
    "def eer(pred, labels):\n",
    "    fpr, tpr, threshold = metrics.roc_curve(labels.detach(), pred.detach(), pos_label=1)\n",
    "    fnr = 1 - tpr\n",
    "    EER_fpr = fpr[numpy.nanargmin(numpy.absolute((fnr - fpr)))]\n",
    "    EER_fnr = fnr[numpy.nanargmin(numpy.absolute((fnr - fpr)))]\n",
    "    return EER_fpr, EER_fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre and after agg function\n",
    "prepNN1 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(5, 5, bias = True),\n",
    "    torch.nn.ReLU(),\n",
    ").double()\n",
    "\n",
    "afterNN1 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(5, 1, bias = True),\n",
    "    torch.nn.Tanh()\n",
    ").double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/kuba/code/aic/mil')\n",
    "from sklearn.datasets import make_classification\n",
    "from mill_python.create_dataset.create_bags_simple import create_bags_simple\n",
    "import numpy\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Create data\n",
    "source_data, source_labels = make_classification(n_samples = 1000, n_features = 5, n_informative = 5, n_redundant = 0, n_repeated = 0, n_classes = 10, class_sep = 1.0, n_clusters_per_class = 1)\n",
    "data, ids, labels = create_bags_simple(source_data, source_labels, pos = 10, neg = 10, max_instances = 5)\n",
    "n_instances = ids2n_instances(torch.Tensor(ids))\n",
    "data_3d = create_3d_data(instances = data, n_instances = n_instances)\n",
    "\n",
    "# Split data on train and test sets\n",
    "labels = numpy.array(labels)\n",
    "data_3d = numpy.array(data_3d)\n",
    "n_instances = numpy.array(n_instances.float())\n",
    "x, x_t, y, y_t, n_instances, n_instances_t = data_split_3d(data_3d, labels, n_instances, shuffle = True)\n",
    "\n",
    "# # Mask identifying valid instances\n",
    "# mask = torch.zeros(size = (len(n_instances), max(n_instances), len(data[0])))\n",
    "# for i, n in enumerate(n_instances):\n",
    "#     mask[i][:n] = 1\n",
    "    \n",
    "# Init model\n",
    "model = BagModel_3d(prepNN1, afterNN1, torch.mean)\n",
    "model = model.double()\n",
    "\n",
    "# Criterion and optimizer\n",
    "import mill_python.src.mil_pytorch as mil\n",
    "\n",
    "criterion = mil.MyHingeLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  50 loss: 0.6791547673166007\n",
      "step: 100 loss: 0.5880248398068132\n",
      "step: 150 loss: 0.5318041447066791\n",
      "step: 200 loss: 0.49816814553246713\n",
      "step: 250 loss: 0.47753366916092216\n",
      "step: 300 loss: 0.464933341360306\n",
      "step: 350 loss: 0.4569306426651829\n",
      "step: 400 loss: 0.45160790962241515\n",
      "step: 450 loss: 0.4481721357412302\n",
      "step: 500 loss: 0.4458142151876857\n",
      "step: 550 loss: 0.4438326964526862\n",
      "step: 600 loss: 0.442503700835299\n",
      "step: 650 loss: 0.44158862594398074\n",
      "step: 700 loss: 0.4409173565702567\n",
      "step: 750 loss: 0.4404101642305027\n",
      "step: 800 loss: 0.4400244221244419\n",
      "step: 850 loss: 0.439724144512773\n",
      "step: 900 loss: 0.4394858942831389\n",
      "step: 950 loss: 0.43929384461586035\n",
      "step: 1000 loss: 0.43913695867160285\n",
      "step: 1050 loss: 0.4390073317013165\n",
      "step: 1100 loss: 0.4388991720195094\n",
      "step: 1150 loss: 0.4388081514943746\n",
      "step: 1200 loss: 0.4387309788264032\n",
      "step: 1250 loss: 0.43866511185935503\n",
      "step: 1300 loss: 0.438608564845248\n",
      "step: 1350 loss: 0.43855976999416957\n",
      "step: 1400 loss: 0.43851729522166794\n",
      "step: 1450 loss: 0.4384802336200772\n",
      "step: 1500 loss: 0.4384477699612967\n",
      "step: 1550 loss: 0.4384192297151237\n",
      "step: 1600 loss: 0.43839402559224994\n",
      "step: 1650 loss: 0.4383716650348604\n",
      "step: 1700 loss: 0.4383517318700424\n",
      "step: 1750 loss: 0.4383338731224907\n",
      "step: 1800 loss: 0.43831775881981794\n",
      "step: 1850 loss: 0.4383031607295354\n",
      "step: 1900 loss: 0.4382898450218815\n",
      "step: 1950 loss: 0.4382775544077739\n",
      "step: 2000 loss: 0.4382662567444966\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "print_loss = True\n",
    "\n",
    "x = x.double()\n",
    "n_instances = torch.Tensor(n_instances).long()\n",
    "\n",
    "for epoch in range(2000):\n",
    "    pred = model(x, n_instances)\n",
    "    loss = criterion(pred[:,0], y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print loss every ** epochs\n",
    "    if print_loss and ((epoch+1)%50 == 0):\n",
    "        print('step: {:3d} loss: {}'.format(epoch+1, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train: 0.4382660398383135\n",
      "acc_train: 0.5625\n",
      "eer_fpr_train: 0.2857142857142857\n",
      "eer_fnr_train: 0.33333333333333337\n",
      "loss_test: 0.7500261973394825\n",
      "acc_test: 0.25\n",
      "eer_fpr_test: 0.0\n",
      "eer_fnr_test: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Train set accuracy\n",
    "pred = model(x, n_instances) \n",
    "loss = criterion(pred[:,0], y)\n",
    "eer_fpr, eer_fnr = eer(pred[:,0], y)\n",
    "print('loss_train: {}'.format(loss))\n",
    "print('acc_train: {}'.format(accuracy(pred[:,0], y)))\n",
    "print('eer_fpr_train: {}'.format(eer_fpr))\n",
    "print('eer_fnr_train: {}'.format(eer_fnr))\n",
    "\n",
    "x_t = x_t.double()\n",
    "n_instances_t = torch.Tensor(n_instances_t).long()\n",
    "\n",
    "# Test set accuracy\n",
    "pred = model(x_t, n_instances_t)\n",
    "loss = criterion(pred[:,0], y_t)\n",
    "eer_fpr, eer_fnr = eer(pred[:,0], y_t)\n",
    "print('loss_test: {}'.format(loss))\n",
    "print('acc_test: {}'.format(accuracy(pred[:,0], y_t)))\n",
    "print('eer_fpr_test: {}'.format(eer_fpr))\n",
    "print('eer_fnr_test: {}'.format(eer_fnr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
