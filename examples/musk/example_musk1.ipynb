{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Import mil containing BagModel and MilDataset from mil_pytorch\n",
    "import mil_pytorch.mil as mil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from files\n",
    "data = pandas.read_csv('data_musk1/data.csv', header = None).values\n",
    "ids = pandas.read_csv('data_musk1/ids.csv', squeeze = True, header = None).values\n",
    "labels = pandas.read_csv('data_musk1/labels.csv', squeeze = True, header = None).values\n",
    "\n",
    "# Create tensors containing data\n",
    "data = torch.tensor(data)\n",
    "ids = torch.tensor(ids)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Create instance of MilDataset\n",
    "dataset = mil.MilDataset(data, ids, labels, normalize = True)\n",
    "\n",
    "# Create train and test data loaders (instances of DataLoader)\n",
    "batch_size = 10\n",
    "\n",
    "indices = numpy.arange(len(dataset))\n",
    "train_indices, test_indices = model_selection.train_test_split(indices, shuffle = True,test_size = 0.2)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_dl = DataLoader(dataset, sampler = train_sampler, batch_size = batch_size, collate_fn=mil.collate) # Using custom collate_fn mil.collate\n",
    "test_dl = DataLoader(dataset, sampler = test_sampler, batch_size = len(test_indices), collate_fn=mil.collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model, criterion and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function for criterion\n",
    "class MyHingeLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "        target = target.double()\n",
    "        hinge_loss = 1 - torch.mul(output, target)\n",
    "        hinge_loss[hinge_loss<0] = 0\n",
    "        \n",
    "        return (torch.sum(hinge_loss, dim = 0, keepdim = True) / hinge_loss.size(0))\n",
    "\n",
    "# Model parameters\n",
    "n_neurons = 10\n",
    "input_len = len(dataset.data[0])\n",
    "\n",
    "# Defining neural networks for proccesing inputs before and after aggregation function\n",
    "prepNN = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_len, n_neurons, bias = True),\n",
    "    torch.nn.ReLU(),\n",
    ")\n",
    "\n",
    "afterNN = torch.nn.Sequential(\n",
    "    torch.nn.Linear(n_neurons, 1),\n",
    "    torch.nn.Tanh()\n",
    ")\n",
    "\n",
    "# Create model, using custom created prepNN, afterNN and aggregation function\n",
    "model = mil.BagModel(prepNN, afterNN, aggregation_func = torch.mean).double()\n",
    "\n",
    "# Loss function\n",
    "criterion = MyHingeLoss()\n",
    "\n",
    "# Optimizer parameters\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-6\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING:\n",
      "[100/1000] | train_loss: 0.5095319151878357\n",
      "[200/1000] | train_loss: 0.3462904691696167\n",
      "[300/1000] | train_loss: 0.3434804081916809\n",
      "[400/1000] | train_loss: 0.19068318605422974\n",
      "[500/1000] | train_loss: 0.13699862360954285\n",
      "[600/1000] | train_loss: 0.11907389760017395\n",
      "[700/1000] | train_loss: 0.07415377348661423\n",
      "[800/1000] | train_loss: 0.06440272182226181\n",
      "[900/1000] | train_loss: 0.04708762839436531\n",
      "[1000/1000] | train_loss: 0.038948893547058105\n",
      "Finished training - elapsed time: 20.27362608909607\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Training parameters\n",
    "epochs = 1000\n",
    "\n",
    "start = time.time()\n",
    "print('TRAINING:')\n",
    "\n",
    "# Tensor for collecting losses over batches\n",
    "train_losses = torch.empty(0)\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    for data, ids, labels in train_dl:\n",
    "        pred = model((data, ids))\n",
    "        loss = criterion(pred[:,0], labels)\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Save loss on this batch\n",
    "        train_losses = torch.cat((train_losses, loss.float()))\n",
    "    \n",
    "    # Compute avarega loss on this epoch\n",
    "    train_loss = torch.mean(train_losses, dim = 0, keepdim = True)\n",
    "    \n",
    "    # Clear tensor for saving losses over batches\n",
    "    train_losses = torch.empty(0)\n",
    "\n",
    "    # Print info about learning every 100 epochs\n",
    "    if (epoch+1)%100 == 0:\n",
    "        print('[{}/{}] | train_loss: {}'.format(epoch+1, epochs, train_loss.item()))\n",
    "\n",
    "print('Finished training - elapsed time: {}'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION:\n",
      "TRAIN DATA\n",
      "Loss: 0.04240001035528072\n",
      "Accuracy: 98.63%\n",
      "Equal error rate approximation using false positive rate: 0.0286\n",
      "Equal error rate approximation using false negative rate: 0.0\n",
      "TEST DATA\n",
      "Loss: 0.37781251377836034\n",
      "Accuracy: 84.21%\n",
      "Equal error rate approximation using false positive rate: 0.3\n",
      "Equal error rate approximation using false negative rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def eer(pred, labels):\n",
    "    fpr, tpr, threshold = metrics.roc_curve(labels.detach(), pred.detach(), pos_label=1)\n",
    "    fnr = 1 - tpr\n",
    "    EER_fpr = fpr[numpy.nanargmin(numpy.absolute((fnr - fpr)))]\n",
    "    EER_fnr = fnr[numpy.nanargmin(numpy.absolute((fnr - fpr)))]\n",
    "    return EER_fpr, EER_fnr\n",
    "\n",
    "def accuracy(pred, target, threshold = 0):\n",
    "    pred = pred.detach().numpy()\n",
    "    target = target.detach().numpy()\n",
    "\n",
    "    pred[pred >= threshold] = 1\n",
    "    pred[pred < threshold] = -1\n",
    "\n",
    "    return numpy.sum(target == pred)/target.shape[0]\n",
    "\n",
    "print('EVALUATION:')\n",
    "\n",
    "# Train dataloader for evaluation\n",
    "train_dl = DataLoader(dataset, sampler = train_sampler, batch_size = len(train_indices), collate_fn=mil.collate)\n",
    "\n",
    "for data, ids, labels in train_dl:\n",
    "    pred = model((data, ids))\n",
    "    loss = criterion(pred[:,0], labels)\n",
    "    acc = accuracy(pred[:,0], labels)\n",
    "    eer_fpr, eer_fnr = eer(pred[:,0], labels)\n",
    "\n",
    "print('TRAIN DATA')\n",
    "print('Loss: {:6}'.format(loss.item()))\n",
    "print('Accuracy: {:.2%}'.format(acc))\n",
    "print('Equal error rate approximation using false positive rate: {:.3}'.format(eer_fpr))\n",
    "print('Equal error rate approximation using false negative rate: {:.3}'.format(eer_fnr))\n",
    "\n",
    "\n",
    "for data, ids, labels in test_dl:\n",
    "    pred = model((data, ids))\n",
    "    loss = criterion(pred[:,0], labels)\n",
    "    acc = accuracy(pred[:,0], labels)\n",
    "    eer_fpr, eer_fnr = eer(pred[:,0], labels)\n",
    "\n",
    "print('TEST DATA')\n",
    "print('Loss: {:6}'.format(loss.item()))\n",
    "print('Accuracy: {:.2%}'.format(acc))\n",
    "print('Equal error rate approximation using false positive rate: {:.3}'.format(eer_fpr))\n",
    "print('Equal error rate approximation using false negative rate: {:.3}'.format(eer_fnr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
